{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import shutil\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def _chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i : i + n]\n",
    "\n",
    "\n",
    "def generate_csv_test_dataset(\n",
    "    name: str, df: pd.DataFrame, test_datasets_path: pathlib.Path, random_state: int\n",
    ") -> None:\n",
    "    # generate dirs\n",
    "    base_path = test_datasets_path / \"csv\" / name\n",
    "    os.makedirs(base_path, exist_ok=True)\n",
    "    os.makedirs(base_path / \"split\" / \"train\", exist_ok=True)\n",
    "    os.makedirs(base_path / \"split\" / \"test\", exist_ok=True)\n",
    "    os.makedirs(base_path / \"split\" / \"val\", exist_ok=True)\n",
    "    os.makedirs(base_path / \"bad_split\" / \"train\", exist_ok=True)\n",
    "    os.makedirs(base_path / \"bad_split\" / \"test\", exist_ok=True)\n",
    "    os.makedirs(base_path / \"bad_split\" / \"val\", exist_ok=True)\n",
    "    os.makedirs(base_path / \"splits\" / \"train\", exist_ok=True)\n",
    "    os.makedirs(base_path / \"splits\" / \"test\", exist_ok=True)\n",
    "    os.makedirs(base_path / \"splits\" / \"val\", exist_ok=True)\n",
    "\n",
    "    # ---------------------------------------------------------------------------------\n",
    "    # common cases\n",
    "    df.to_csv(base_path / \"comma.csv\", sep=\",\", index=False)\n",
    "    df.to_csv(base_path / \"semicolon.csv\", sep=\";\", index=False)\n",
    "    df.to_csv(base_path / \"tab.csv\", sep=\"\\t\", index=False)\n",
    "    df.to_csv(base_path / \"vertical_bar.csv\", sep=\"|\", index=False)\n",
    "\n",
    "    # ---------------------------------------------------------------------------------\n",
    "    # no header\n",
    "    df.to_csv(\n",
    "        base_path / \"no_header.csv\",\n",
    "        sep=\";\",\n",
    "        header=False,\n",
    "        index=False,\n",
    "    )\n",
    "\n",
    "    # ---------------------------------------------------------------------------------\n",
    "    # bad format\n",
    "    df.to_csv(\n",
    "        path_or_buf=base_path / \"bad_format.csv\",\n",
    "        sep=\";\",\n",
    "        header=False,\n",
    "        index=False,\n",
    "    )\n",
    "    with open(base_path / \"bad_format.csv\", \"w\") as file:\n",
    "        file.write(\"------\")\n",
    "\n",
    "    # ---------------------------------------------------------------------------------\n",
    "    # empty file\n",
    "    with open(base_path / \"empty_file.csv\", \"w\") as file:\n",
    "        file.write(\"\")\n",
    "\n",
    "    # ---------------------------------------------------------------------------------\n",
    "    # empty dataframe\n",
    "    df.head(0).to_csv(\n",
    "        path_or_buf=base_path / \"empty_dataset.csv\",\n",
    "        sep=\";\",\n",
    "        index=False,\n",
    "    )\n",
    "\n",
    "    # ---------------------------------------------------------------------------------\n",
    "    # with splits\n",
    "    train, rest = train_test_split(\n",
    "        df,\n",
    "        train_size=0.334,\n",
    "        stratify=df.target,\n",
    "        random_state=random_state,\n",
    "    )\n",
    "    test, val = train_test_split(\n",
    "        rest,\n",
    "        train_size=0.5,\n",
    "        stratify=rest.target,\n",
    "        random_state=random_state,\n",
    "    )\n",
    "\n",
    "    train.to_csv(\n",
    "        path_or_buf=base_path / \"split\" / \"train\" / \"train.csv\",\n",
    "        sep=\";\",\n",
    "        index=False,\n",
    "    )\n",
    "    test.to_csv(\n",
    "        path_or_buf=base_path / \"split\" / \"test\" / \"test.csv\",\n",
    "        sep=\";\",\n",
    "        index=False,\n",
    "    )\n",
    "    val.to_csv(\n",
    "        path_or_buf=base_path / \"split\" / \"val\" / \"val.csv\",\n",
    "        sep=\";\",\n",
    "        index=False,\n",
    "    )\n",
    "    shutil.make_archive(str(base_path / \"split.zip\"), \"zip\", base_path / \"split\")\n",
    "\n",
    "    # ---------------------------------------------------------------------------------\n",
    "    # with splits but bad folders\n",
    "    train.to_csv(\n",
    "        path_or_buf=base_path / \"bad_split\" / \"train.csv\",\n",
    "        sep=\";\",\n",
    "        index=False,\n",
    "    )\n",
    "    test.to_csv(\n",
    "        path_or_buf=base_path / \"bad_split\" / \"test.csv\",\n",
    "        sep=\";\",\n",
    "        index=False,\n",
    "    )\n",
    "    val.to_csv(\n",
    "        path_or_buf=base_path / \"bad_split\" / \"val.csv\",\n",
    "        sep=\";\",\n",
    "        index=False,\n",
    "    )\n",
    "    shutil.make_archive(\n",
    "        str(base_path / \"bad_split.zip\"),\n",
    "        \"zip\",\n",
    "        base_path / \"bad_split\",\n",
    "    )\n",
    "\n",
    "    # ---------------------------------------------------------------------------------\n",
    "    # with several splits\n",
    "    def get_start_end_idx(df, n, i):\n",
    "        start_idx = int(i * len(df) / n)\n",
    "        end_idx = min(int((i + 1) * len(df) / n), len(df))\n",
    "        return start_idx, end_idx\n",
    "\n",
    "    n = 5\n",
    "    for i in range(n - 1):\n",
    "        train_start, train_end = get_start_end_idx(train, n, i)\n",
    "        train.iloc[train_start:train_end].to_csv(\n",
    "            path_or_buf=base_path / \"splits\" / \"train\" / f\"train_{i}.csv\",\n",
    "            sep=\";\",\n",
    "            index=False,\n",
    "        )\n",
    "\n",
    "        test_start, test_end = get_start_end_idx(test, n, i)\n",
    "        test.iloc[test_start:test_end].to_csv(\n",
    "            path_or_buf=base_path / \"splits\" / \"test\" / f\"test_{i}.csv\",\n",
    "            sep=\";\",\n",
    "            index=False,\n",
    "        )\n",
    "\n",
    "        val_start, val_end = get_start_end_idx(test, n, i)\n",
    "        val.iloc[val_start:val_end].to_csv(\n",
    "            path_or_buf=base_path / \"splits\" / \"val\" / f\"val_{i}.csv\",\n",
    "            sep=\";\",\n",
    "            index=False,\n",
    "        )\n",
    "    shutil.make_archive(\n",
    "        str(base_path / \"splits.zip\"),\n",
    "        \"zip\",\n",
    "        base_path / \"splits\",\n",
    "    )\n",
    "\n",
    "    # TODO: splits with one error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris, load_wine\n",
    "\n",
    "TEST_DATASETS_PATH = pathlib.Path(\"./test_datasets\")\n",
    "RANDOM_STATE = 50\n",
    "\n",
    "os.makedirs(TEST_DATASETS_PATH, exist_ok=True)\n",
    "with open(TEST_DATASETS_PATH / \".gitignore\", \"w\") as f:\n",
    "    f.write(\"*\")\n",
    "\n",
    "df_iris = load_iris(return_X_y=False, as_frame=True)[\"frame\"]\n",
    "generate_csv_test_dataset(\n",
    "    \"iris\",\n",
    "    df=df_iris,\n",
    "    test_datasets_path=TEST_DATASETS_PATH,\n",
    "    random_state=RANDOM_STATE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wine = load_wine(return_X_y=False, as_frame=True)[\"frame\"]\n",
    "generate_csv_test_dataset(\"wine\", df=df_wine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'itertools' has no attribute 'batched'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mitertools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatched\u001b[49m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m50\u001b[39m), n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m3\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'itertools' has no attribute 'batched'"
     ]
    }
   ],
   "source": [
    "[lst[i : i + n] for i in range(0, len(lst), n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2]\n",
      "[3, 4, 5]\n",
      "[6, 7, 8]\n",
      "[9, 10, 11]\n",
      "[12, 13, 14]\n",
      "[15, 16, 17]\n",
      "[18, 19, 20]\n",
      "[21, 22, 23]\n",
      "[24, 25, 26]\n",
      "[27, 28, 29]\n",
      "[30, 31, 32]\n",
      "[33, 34, 35]\n",
      "[36, 37, 38]\n",
      "[39, 40, 41]\n",
      "[42, 43, 44]\n",
      "[45, 46, 47]\n",
      "[48, 49, 50]\n",
      "[51, 52, 53]\n",
      "[54, 55, 56]\n",
      "[57, 58, 59]\n",
      "[60, 61, 62]\n",
      "[63, 64, 65]\n",
      "[66, 67, 68]\n",
      "[69, 70, 71]\n",
      "[72, 73, 74]\n",
      "[75, 76, 77]\n",
      "[78, 79, 80]\n",
      "[81, 82, 83]\n",
      "[84, 85, 86]\n",
      "[87, 88, 89]\n",
      "[90, 91, 92]\n",
      "[93, 94, 95]\n",
      "[96, 97, 98]\n",
      "[99, 100, 101]\n",
      "[102, 103, 104]\n",
      "[105, 106, 107]\n",
      "[108, 109, 110]\n",
      "[111, 112, 113]\n",
      "[114, 115, 116]\n",
      "[117, 118, 119]\n",
      "[120, 121, 122]\n",
      "[123, 124, 125]\n",
      "[126, 127, 128]\n",
      "[129, 130, 131]\n",
      "[132, 133, 134]\n",
      "[135, 136, 137]\n",
      "[138, 139, 140]\n",
      "[141, 142, 143]\n",
      "[144, 145, 146]\n",
      "[147, 148, 149]\n"
     ]
    }
   ],
   "source": [
    "for i in chunks(range(150), 3):\n",
    "    print(list(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dashai38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
